{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Chainer](http://chainer.org/) とはニューラルネットの実装を簡単にしたフレームワークです。\n",
    "\n",
    "* 今回は機械翻訳にニューラルネットを適用してみました。\n",
    "\n",
    "![](./pictures/Chainer.jpg)\n",
    "\n",
    "* 今回は機械翻訳を行っていただきます。\n",
    "\n",
    "機械翻訳は機械が言語を別の言語に翻訳するものです。\n",
    "\n",
    "機械翻訳にはいくつか種類があるのでここでも紹介しておきます。\n",
    "\n",
    "* PBMT(Phrase Base Machine Translation)モデル\n",
    " * [moses](http://www.statmt.org/moses/)というオープンソースで使用できるメジャーな機械翻訳のモデルですが、難しすぎて理解できない人を続出させる機械翻訳の鬼門です\n",
    "* ニューラル機械翻訳\n",
    " * 翻訳元単語の辞書ベクトルを潜在空間ベクトルに落とし込み、ニューラルネットで翻訳先言語を学習させる手法\n",
    "\n",
    "以下では、このChainerを利用しデータを準備するところから実際に言語モデルを構築し学習・評価を行うまでの手順を解説します。\n",
    "\n",
    "1. [各種ライブラリ導入](#各種ライブラリ導入) \n",
    "2. [機械翻訳のクラス](#機械翻訳のクラス)\n",
    "3. [翻訳処理を行うforward処理部分](#翻訳処理を行うforward処理部分)\n",
    "4. [各値を設定](#各値を設定)\n",
    "5. [実行](#実行)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.各種ライブラリ導入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerの言語処理では多数のライブラリを導入します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util.functions import trace\n",
    "\n",
    "from util.chainer_cpu_wrapper import wrapper\n",
    "\n",
    "from EncoderDecoderModel import EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`導入するライブラリの代表例は下記です。\n",
    "\n",
    "* `numpy`: 行列計算などの複雑な計算を行なうライブラリ\n",
    "* `chainer`: Chainerの導入\n",
    "* `util`:今回の処理で必要なライブラリが入っています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.機械翻訳のクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記を設定しています。\n",
    "* ニューラルネットを用いて機械翻訳用のモデルを構成しています。\n",
    "\n",
    "全体構成\n",
    "\n",
    "![](./pictures/NN_machine_translation.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.翻訳処理を行うforward処理部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記の論文を参考にしてforward処理を記述しています。\n",
    "\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "* Encoder部分\n",
    "もっとも特徴的な部分は翻訳元言語を逆順にしていることです。そうすることで精度が向上していると述べており、今回の翻訳のNNモデルもそれを再現しています。\n",
    "\n",
    "この論文でははっきりした要因はわかっていないが、おそらく翻訳先の言語と翻訳元言語の距離が逆順にすることで最初の単語の距離が近くなり、翻訳のタイムラグが少なくなったことが起因していると考えられています。\n",
    "\n",
    "![](./pictures/encoder.png)\n",
    "\n",
    "* Decoder部分\n",
    "\n",
    "学習部分と予測部分を実装しています。学習部分ではターゲット先の単語の取得と損失の計算をしています。\n",
    "またlstmで次回の学習に使用する部分では学習では正解の翻訳、予測では予測した翻訳を使用しています。\n",
    "\n",
    "![](./pictures/decorder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderModelForward(EncoderDecoderModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __forward(self, is_training, src_batch, trg_batch = None, generation_limit = None):\n",
    "        m = self.__model\n",
    "        tanh = functions.tanh\n",
    "        lstm = functions.lstm\n",
    "        batch_size = len(src_batch)\n",
    "        src_len = len(src_batch[0])\n",
    "        src_stoi = self.__src_vocab.stoi\n",
    "        trg_stoi = self.__trg_vocab.stoi\n",
    "        trg_itos = self.__trg_vocab.itos\n",
    "        s_c = wrapper.zeros((batch_size, self.__n_hidden))\n",
    "\n",
    "#--------Hands on------------------------------------------------------------------#\n",
    "\n",
    "        # encoding\n",
    "        s_x = wrapper.make_var([src_stoi('</s>') for _ in range(batch_size)], dtype=np.int32)\n",
    "        s_i = tanh(m.w_xi(s_x))\n",
    "        s_c, s_p = lstm(s_c, m.w_ip(s_i))\n",
    "\n",
    "        for l in reversed(range(src_len)):\n",
    "            s_x = wrapper.make_var([src_stoi(src_batch[k][l]) for k in range(batch_size)], dtype=np.int32)\n",
    "            s_i = tanh(m.w_xi(s_x))\n",
    "            s_c, s_p = lstm(s_c, m.w_ip(s_i) + m.w_pp(s_p))\n",
    "\n",
    "        s_c, s_q = lstm(s_c, m.w_pq(s_p))\n",
    "        hyp_batch = [[] for _ in range(batch_size)]\n",
    "\n",
    "        # decoding\n",
    "        if is_training:\n",
    "            accum_loss = wrapper.zeros(())\n",
    "            trg_len = len(trg_batch[0])\n",
    "\n",
    "            for l in range(trg_len):\n",
    "                s_j = tanh(m.w_qj(s_q))\n",
    "                r_y = m.w_jy(s_j)\n",
    "                s_t = wrapper.make_var([trg_stoi(trg_batch[k][l]) for k in range(batch_size)], dtype=np.int32)\n",
    "                accum_loss += functions.softmax_cross_entropy(r_y, s_t)\n",
    "                output = wrapper.get_data(r_y).argmax(1)\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    hyp_batch[k].append(trg_itos(output[k]))\n",
    "\n",
    "                s_c, s_q = lstm(s_c, m.w_yq(s_t) + m.w_qq(s_q))\n",
    "\n",
    "            return hyp_batch, accum_loss\n",
    "        else:\n",
    "            while len(hyp_batch[0]) < generation_limit:\n",
    "                s_j = tanh(m.w_qj(s_q))\n",
    "                r_y = m.w_jy(s_j)\n",
    "                output = wrapper.get_data(r_y).argmax(1)\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    hyp_batch[k].append(trg_itos(output[k]))\n",
    "\n",
    "                if all(hyp_batch[k][-1] == '</s>' for k in range(batch_size)): break\n",
    "\n",
    "                s_y = wrapper.make_var(output, dtype=np.int32)\n",
    "                s_c, s_q = lstm(s_c, m.w_yq(s_y) + m.w_qq(s_q))\n",
    "\n",
    "            return hyp_batch\n",
    "        \n",
    "#--------Hands on------------------------------------------------------------------#\n",
    "        \n",
    "    def train(self, src_batch, trg_batch):\n",
    "        self.__opt.zero_grads()\n",
    "        hyp_batch, accum_loss = self.__forward(True, src_batch, trg_batch=trg_batch)\n",
    "        accum_loss.backward()\n",
    "        self.__opt.clip_grads(10)\n",
    "        self.__opt.update()\n",
    "        return hyp_batch\n",
    "\n",
    "    def predict(self, src_batch, generation_limit):\n",
    "        return self.__forward(False, src_batch, generation_limit=generation_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.各値を設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各値を設定\n",
    "\n",
    "* モードを学習かテストか設定\n",
    "* 翻訳元言語の設定\n",
    "* 翻訳先言語の設定\n",
    "* 語彙の設定\n",
    "* 潜在空間の設定\n",
    "* 隠れ層の設定\n",
    "* 学習回数の設定\n",
    "* ミニバッチサイズの設定\n",
    "* 最大予測言語数の設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_dict = {}\n",
    "mode = \"train\"\n",
    "#--------Hands on  2----------------------------------------------------------------#\n",
    "parameter_dict[\"source\"] = \"source_wakati_kytea.txt\"\n",
    "parameter_dict[\"target\"] = \"target_stanford_parse.txt\"\n",
    "parameter_dict[\"vocab\"] = 32768\n",
    "parameter_dict[\"embed\"] = 256\n",
    "parameter_dict[\"hidden\"] = 512\n",
    "parameter_dict[\"epoch\"] = 100\n",
    "parameter_dict[\"minibatch\"] = 64\n",
    "parameter_dict[\"generation_limit\"] = 256\n",
    "#--------Hands on  2----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    trace('initializing ...')\n",
    "    wrapper.init()\n",
    "\n",
    "    encoderDecoderModel = EncoderDecoderModel(parameter_dict)\n",
    "    if mode == 'train': encoderDecoderModel.train_model()\n",
    "    elif mode == 'test': encoderDecoderModel.test_model()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
