{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Chainer](http://chainer.org/) とはニューラルネットの実装を簡単にしたフレームワークです。\n",
    "\n",
    "* 今回は機械翻訳にニューラルネットを適用してみました。\n",
    "\n",
    "![](./pictures/Chainer.jpg)\n",
    "\n",
    "* 今回は機械翻訳を行っていただきます。\n",
    "\n",
    "ハンズオンについての説明\n",
    "http://qiita.com/GushiSnow/private/b0abf7d3dccafe14fa07\n",
    "\n",
    "機械翻訳は機械が言語を別の言語に翻訳するものです。\n",
    "\n",
    "機械翻訳にはいくつか種類があるのでここでも紹介しておきます。\n",
    "\n",
    "* PBMT(Phrase Base Machine Translation)モデル\n",
    " * [moses](http://www.statmt.org/moses/)というオープンソースで使用できるメジャーな機械翻訳のモデルですが、難しすぎて理解できない人を続出させる機械翻訳の鬼門です\n",
    "* ニューラル機械翻訳\n",
    " * 翻訳元単語の辞書ベクトルを潜在空間ベクトルに落とし込み、ニューラルネットで翻訳先言語を学習させる手法\n",
    "\n",
    "以下では、このChainerを利用しデータを準備するところから実際にNN翻訳モデルを構築し学習・評価を行うまでの手順を解説します。\n",
    "\n",
    "1. [各種ライブラリ導入](#各種ライブラリ導入) \n",
    "2. [機械翻訳のクラス](#機械翻訳のクラス)\n",
    "3. [翻訳処理を行うforwardに必要なパラメータ設定](#翻訳処理を行うforwardに必要なパラメータ設定)\n",
    "4. [翻訳処理を行うEncoder処理部分](#翻訳処理を行うEncoder処理部分)\n",
    "5. [翻訳処理を行うDecoder処理部分](#翻訳処理を行うDecoder処理部分)\n",
    "6. [翻訳処理を行うforward処理部分](#翻訳処理を行うforward処理部分)\n",
    "7. [各値を設定](#各値を設定)\n",
    "8. [実行](#実行)\n",
    "9. [学習したモデルを使用したテスト (Advanced)](#学習したモデルを使用したテスト (Advanced))\n",
    "10. [学習したモデルを評価 (Advanced)](#学習したモデルを評価 (Advanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.各種ライブラリ導入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerの言語処理では多数のライブラリを導入します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util.functions import trace\n",
    "import numpy as np\n",
    "\n",
    "from chainer import functions, optimizers\n",
    "\n",
    "from util.chainer_cpu_wrapper import wrapper\n",
    "\n",
    "from EncoderDecoderModel import EncoderDecoderModel\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`導入するライブラリの代表例は下記です。\n",
    "\n",
    "* `numpy`: 行列計算などの複雑な計算を行なうライブラリ\n",
    "* `chainer`: Chainerの導入\n",
    "* `util`:今回の処理で必要なライブラリが入っています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.機械翻訳のクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記を設定しています。\n",
    "* ニューラルネットを用いて機械翻訳用のモデルを構成しています。\n",
    "\n",
    "全体構成\n",
    "\n",
    "![](./pictures/NN_machine_translation.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.翻訳処理を行うforwardに必要なパラメータ設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のコードで必要なパラメータを設定するクラスを定義しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderModelParameter():\n",
    "    \n",
    "    def __init__(self, is_training, src_batch, encoderDecoderModel, trg_batch = None, generation_limit = None):\n",
    "        self.m = encoderDecoderModel.model\n",
    "        self.tanh = functions.tanh\n",
    "        self.lstm = functions.lstm\n",
    "        self.batch_size = len(src_batch)\n",
    "        self.src_len = len(src_batch[0])\n",
    "        self.src_stoi = encoderDecoderModel.src_vocab.stoi\n",
    "        self.trg_stoi = encoderDecoderModel.trg_vocab.stoi\n",
    "        self.trg_itos = encoderDecoderModel.trg_vocab.itos\n",
    "        self.state_c = wrapper.zeros((self.batch_size, encoderDecoderModel.n_hidden))\n",
    "        self.trg_batch = trg_batch\n",
    "        self.generation_limit = generation_limit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.翻訳処理を行うEncoder処理部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記の論文を参考にしてforward処理を記述しています。\n",
    "\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "* Encoder部分\n",
    "もっとも特徴的な部分は翻訳元言語を逆順にしていることです。そうすることで精度が向上していると述べており、今回の翻訳のNNモデルもそれを再現しています。\n",
    "\n",
    "この論文でははっきりした要因はわかっていないが、おそらく翻訳先の言語と翻訳元言語の距離が逆順にすることで最初の単語の距離が近くなり、翻訳のタイムラグが少なくなったことが起因していると考えられています。\n",
    "\n",
    "![](./pictures/encoder.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderModelEncoding():\n",
    "    \n",
    "    def encoding(self, src_batch, parameter, trg_batch = None, generation_limit = None):\n",
    "\n",
    "#--------Hands on------------------------------------------------------------------#\n",
    "    # encoding\n",
    "        #翻訳元言語の末尾</s>を潜在空間に写像し、隠れ層に入力、lstmで出力までをバッチサイズ分行う。\n",
    "        state_x = wrapper.make_var([parameter.src_stoi('</s>') for _ in range(parameter.batch_size)], dtype=np.int32)\n",
    "        state_i = parameter.tanh(parameter.m.w_xi(state_x))\n",
    "        parameter.status_c, state_p = parameter.lstm(parameter.state_c, parameter.m.w_ip(state_i))\n",
    "        \n",
    "        #翻訳元言語を逆順に１と同様の処理を行う。   \n",
    "        for l in reversed(range(parameter.src_len)):\n",
    "            #翻訳元言語を語彙空間に写像\n",
    "            state_x = wrapper.make_var([parameter.src_stoi(src_batch[k][l]) for k in range(parameter.batch_size)], dtype=np.int32)\n",
    "            #語彙空間を潜在空間（次元数が減る）に写像\n",
    "            state_i = parameter.tanh(parameter.m.w_xi(state_x))\n",
    "            #状態と出力結果をlstmにより出力。lstmの入力には前の状態と語彙空間の重み付き出力と前回の重み付き出力を入力としている\n",
    "            parameter.state_c, state_p = parameter.lstm(parameter.status_c, parameter.m.w_ip(state_i) + parameter.m.w_pp(state_p))\n",
    "\n",
    "        #次のミニバッチ処理のために最終結果をlstmで出力。翻訳の仮説用のリストを保持\n",
    "        parameter.state_c, state_q = parameter.lstm(parameter.state_c, parameter.m.w_pq(state_p))\n",
    "        hyp_batch = [[] for _ in range(parameter.batch_size)]\n",
    "        return state_q, hyp_batch\n",
    "#--------Hands on------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.翻訳処理を行うDecoder処理部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decoder部分\n",
    "\n",
    "学習部分と予測部分を実装しています。学習部分ではターゲット先の単語の取得と損失の計算をしています。\n",
    "またlstmで次回の学習に使用する部分では学習では正解の翻訳、予測では予測した翻訳を使用しています。\n",
    "\n",
    "![](./pictures/decorder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderModelDecoding():\n",
    "    \n",
    "    def decoding(self, is_training, src_batch, parameter, s_q, hyp_batch, trg_batch = None, generation_limit = None):\n",
    "\n",
    "#--------Hands on------------------------------------------------------------------#\n",
    "    # decoding\n",
    "        \"\"\"\n",
    "　　     学習と予測をコードしている。\n",
    "        \"\"\"\n",
    "        if is_training:\n",
    "            #損失の初期化及び答えとなる翻訳先言語の長さを取得。（翻訳元言語と翻訳先言語で長さが異なるため）\n",
    "            accum_loss = wrapper.zeros(())\n",
    "            trg_len = len(parameter.trg_batch[0])\n",
    "\n",
    "            #ニューラルネットの処理は基本的にEncodingと同一であるが、損失計算と翻訳仮説候補の確保の処理が加わっている。\n",
    "            for l in range(trg_len):\n",
    "                #翻訳元言語からのニューラルの出力を受け取り、潜在空間に写像。\n",
    "                s_j = parameter.tanh(parameter.m.w_qj(s_q))\n",
    "                #潜在空間から翻訳先言語の空間に写像\n",
    "                r_y = parameter.m.w_jy(s_j)\n",
    "                #答えとなる翻訳結果を取得\n",
    "                s_t = wrapper.make_var([parameter.trg_stoi(parameter.trg_batch[k][l]) for k in range(parameter.batch_size)], dtype=np.int32)\n",
    "                #損失計算\n",
    "                accum_loss += functions.softmax_cross_entropy(r_y, s_t)\n",
    "                #翻訳仮説出力\n",
    "                output = wrapper.get_data(r_y).argmax(1)\n",
    "\n",
    "                #翻訳仮説確保\n",
    "                for k in range(parameter.batch_size):\n",
    "                    hyp_batch[k].append(parameter.trg_itos(output[k]))\n",
    "\n",
    "                #状態と出力結果をlstmにより出力。lstmの入力には前の状態と語彙空間の重み付き出力と前回の重み付き出力を入力としている\n",
    "                parameter.status_c, s_q = parameter.lstm(parameter.status_c, parameter.m.w_yq(s_t) + parameter.m.w_qq(s_q))\n",
    "            return hyp_batch, accum_loss\n",
    "        else:\n",
    "            \"\"\"\n",
    "            予測部分\n",
    "            \"\"\"\n",
    "            #予測では予測する翻訳言語の長さに制約をしないとニューラル翻訳モデルの性質上、無限に翻訳してしまう可能性があるので、長さに制約を設けている。\n",
    "            while len(hyp_batch[0]) < parameter.generation_limit:\n",
    "                s_j = parameter.tanh(parameter.m.w_qj(s_q))\n",
    "                r_y = parameter.m.w_jy(s_j)\n",
    "                output = wrapper.get_data(r_y).argmax(1)\n",
    "\n",
    "                #翻訳仮説確保\n",
    "                for k in range(parameter.batch_size):\n",
    "                    hyp_batch[k].append(parameter.trg_itos(output[k]))\n",
    "\n",
    "                #ミニバッチサイズ分の翻訳仮説の末尾が</s>になったときにDecoding処理が終わるようになっている。\n",
    "                if all(hyp_batch[k][-1] == '</s>' for k in range(parameter.batch_size)): break\n",
    "                \n",
    "                #次のlstmの処理のために出力結果と状態を渡している\n",
    "                s_y = wrapper.make_var(output, dtype=np.int32)\n",
    "                parameter.status_c, s_q = parameter.lstm(parameter.status_c, parameter.m.w_yq(s_y) + parameter.m.w_qq(s_q))\n",
    "\n",
    "            return hyp_batch\n",
    "        \n",
    "#--------Hands on------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.翻訳処理を行うforward処理部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の処理を実行するためのメソッドです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderModelForward(EncoderDecoderModel):\n",
    "    \n",
    "    def forward(self, is_training, src_batch, trg_batch = None, generation_limit = None):\n",
    "        parameter = EncoderDecoderModelParameter(is_training, src_batch, self, trg_batch, generation_limit)\n",
    "        \n",
    "    # encoding\n",
    "        encoder = EncoderDecoderModelEncoding()\n",
    "        s_q, hyp_batch = encoder.encoding(src_batch, parameter)\n",
    "    # decoding\n",
    "        decoder = EncoderDecoderModelDecoding()\n",
    "        if is_training:\n",
    "            return decoder.decoding(is_training, src_batch, parameter, s_q, hyp_batch, trg_batch, generation_limit)\n",
    "        else:\n",
    "            return decoder.decoding(is_training, src_batch, parameter, s_q, hyp_batch, trg_batch, generation_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.各値を設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各値を設定\n",
    "\n",
    "* 翻訳元言語の設定\n",
    "* 翻訳先言語の設定\n",
    "* 語彙の設定\n",
    "* 潜在空間の設定\n",
    "* 隠れ層の設定\n",
    "* 学習回数の設定\n",
    "* ミニバッチサイズの設定\n",
    "* 最大予測言語数の設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_dict = {}\n",
    "train_path = \"oda201512handson/train/\"\n",
    "test_path = \"oda201512handson/test/\"\n",
    "#--------Hands on  2----------------------------------------------------------------\n",
    "# #\n",
    "\n",
    "parameter_dict[\"source\"] = train_path + \"train1000.ja\"\n",
    "parameter_dict[\"target\"] = train_path + \"train1000.en\"\n",
    "parameter_dict[\"test_source\"] = test_path + \"test1000.ja\"\n",
    "parameter_dict[\"test_target\"] = test_path + \"test1000_hyp.en\"\n",
    "parameter_dict[\"reference_target\"] = test_path + \"test1000.en\"\n",
    "parameter_dict[\"vocab\"] = 550\n",
    "parameter_dict[\"embed\"] = 500\n",
    "parameter_dict[\"hidden\"] = 20\n",
    "parameter_dict[\"epoch\"] = 20\n",
    "parameter_dict[\"minibatch\"] = 64\n",
    "parameter_dict[\"generation_limit\"] = 256\n",
    "parameter_dict[\"show_hands_on_number\"] = 10\n",
    "parameter_dict[\"show_i_epoch\"] = 0\n",
    "#--------Hands on  2----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015-12-08 18:31:49.553484 ... initializing ...\n",
      "2015-12-08 18:31:49.554355 ... making vocaburaries ...\n",
      "2015-12-08 18:31:49.583882 ... making model ...\n",
      "2015-12-08 18:31:49.615206 ... epoch 1/20: \n",
      "2015-12-08 18:31:49.744711 ... epoch   1/ 20, sample       24\n",
      "2015-12-08 18:31:49.745071 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:31:49.745364 ...   trg = he saw it also . *\n",
      "2015-12-08 18:31:49.745594 ...   hyp = several isn almost not it early\n",
      "2015-12-08 18:31:51.727287 ... saving model ...\n",
      "2015-12-08 18:31:52.344344 ... epoch 2/20: \n",
      "2015-12-08 18:31:52.503455 ... epoch   2/ 20, sample       24\n",
      "2015-12-08 18:31:52.503855 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:31:52.504211 ...   trg = he saw it also . *\n",
      "2015-12-08 18:31:52.504472 ...   hyp = he is <unk> is <unk> *\n",
      "2015-12-08 18:31:55.248103 ... saving model ...\n",
      "2015-12-08 18:31:55.802383 ... epoch 3/20: \n",
      "2015-12-08 18:31:55.913131 ... epoch   3/ 20, sample       24\n",
      "2015-12-08 18:31:55.913482 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:31:55.913775 ...   trg = he saw it also . *\n",
      "2015-12-08 18:31:55.914004 ...   hyp = he is <unk> <unk> to *\n",
      "2015-12-08 18:31:57.871162 ... saving model ...\n",
      "2015-12-08 18:31:58.399631 ... epoch 4/20: \n",
      "2015-12-08 18:31:58.508649 ... epoch   4/ 20, sample       24\n",
      "2015-12-08 18:31:58.509003 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:31:58.509294 ...   trg = he saw it also . *\n",
      "2015-12-08 18:31:58.509524 ...   hyp = he is <unk> <unk> to *\n",
      "2015-12-08 18:32:00.469101 ... saving model ...\n",
      "2015-12-08 18:32:01.004730 ... epoch 5/20: \n",
      "2015-12-08 18:32:01.114102 ... epoch   5/ 20, sample       24\n",
      "2015-12-08 18:32:01.114453 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:01.114748 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:01.114979 ...   hyp = he is <unk> <unk> to *\n",
      "2015-12-08 18:32:03.055139 ... saving model ...\n",
      "2015-12-08 18:32:03.573437 ... epoch 6/20: \n",
      "2015-12-08 18:32:03.688170 ... epoch   6/ 20, sample       24\n",
      "2015-12-08 18:32:03.688562 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:03.688820 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:03.689114 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:05.619080 ... saving model ...\n",
      "2015-12-08 18:32:06.152389 ... epoch 7/20: \n",
      "2015-12-08 18:32:06.267029 ... epoch   7/ 20, sample       24\n",
      "2015-12-08 18:32:06.267415 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:06.267745 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:06.268004 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:08.258790 ... saving model ...\n",
      "2015-12-08 18:32:08.784043 ... epoch 8/20: \n",
      "2015-12-08 18:32:08.893784 ... epoch   8/ 20, sample       24\n",
      "2015-12-08 18:32:08.894150 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:08.894445 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:08.894679 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:10.869821 ... saving model ...\n",
      "2015-12-08 18:32:11.390401 ... epoch 9/20: \n",
      "2015-12-08 18:32:11.498841 ... epoch   9/ 20, sample       24\n",
      "2015-12-08 18:32:11.499434 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:11.499950 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:11.500226 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:13.441382 ... saving model ...\n",
      "2015-12-08 18:32:13.958742 ... epoch 10/20: \n",
      "2015-12-08 18:32:14.071134 ... epoch  10/ 20, sample       24\n",
      "2015-12-08 18:32:14.071486 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:14.071723 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:14.071951 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:16.034925 ... saving model ...\n",
      "2015-12-08 18:32:16.551591 ... epoch 11/20: \n",
      "2015-12-08 18:32:16.667026 ... epoch  11/ 20, sample       24\n",
      "2015-12-08 18:32:16.667405 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:16.667723 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:16.667968 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:18.613342 ... saving model ...\n",
      "2015-12-08 18:32:19.147433 ... epoch 12/20: \n",
      "2015-12-08 18:32:19.261954 ... epoch  12/ 20, sample       24\n",
      "2015-12-08 18:32:19.262339 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:19.262600 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:19.262882 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:21.208824 ... saving model ...\n",
      "2015-12-08 18:32:21.741950 ... epoch 13/20: \n",
      "2015-12-08 18:32:21.852230 ... epoch  13/ 20, sample       24\n",
      "2015-12-08 18:32:21.852610 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:21.852996 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:21.853360 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:23.807613 ... saving model ...\n",
      "2015-12-08 18:32:24.330660 ... epoch 14/20: \n",
      "2015-12-08 18:32:24.442694 ... epoch  14/ 20, sample       24\n",
      "2015-12-08 18:32:24.443044 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:24.443336 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:24.443563 ...   hyp = he is a <unk> to *\n",
      "2015-12-08 18:32:26.382501 ... saving model ...\n",
      "2015-12-08 18:32:26.912979 ... epoch 15/20: \n",
      "2015-12-08 18:32:27.025303 ... epoch  15/ 20, sample       24\n",
      "2015-12-08 18:32:27.025709 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:27.026063 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:27.026327 ...   hyp = he is a a to *\n",
      "2015-12-08 18:32:28.947778 ... saving model ...\n",
      "2015-12-08 18:32:29.471591 ... epoch 16/20: \n",
      "2015-12-08 18:32:29.588456 ... epoch  16/ 20, sample       24\n",
      "2015-12-08 18:32:29.588882 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:29.589181 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:29.589518 ...   hyp = he is a a to *\n",
      "2015-12-08 18:32:31.525821 ... saving model ...\n",
      "2015-12-08 18:32:32.050532 ... epoch 17/20: \n",
      "2015-12-08 18:32:32.164954 ... epoch  17/ 20, sample       24\n",
      "2015-12-08 18:32:32.165382 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:32.165848 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:32.166508 ...   hyp = he is a a to *\n",
      "2015-12-08 18:32:34.182548 ... saving model ...\n",
      "2015-12-08 18:32:34.715650 ... epoch 18/20: \n",
      "2015-12-08 18:32:34.830096 ... epoch  18/ 20, sample       24\n",
      "2015-12-08 18:32:34.830445 ...   src = 彼 も それ を 見 た 。 * * * * * * *\n",
      "2015-12-08 18:32:34.830775 ...   trg = he saw it also . *\n",
      "2015-12-08 18:32:34.831034 ...   hyp = he is a a to *\n"
     ]
    }
   ],
   "source": [
    "trace('initializing ...')\n",
    "wrapper.init()\n",
    "\n",
    "encoderDecoderModel = EncoderDecoderModelForward(parameter_dict)\n",
    "encoderDecoderModel.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.学習したモデルを使用したテスト "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルを使用してテスト\n",
    "\n",
    "* 学習したモデルを利用してテストデータ（日本語）を英語に翻訳しモデルに保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"ChainerMachineTranslation.021\"\n",
    "trace('initializing ...')\n",
    "wrapper.init()\n",
    "\n",
    "encoderDecoderModel = EncoderDecoderModelForward(parameter_dict)\n",
    "encoderDecoderModel.test_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.学習したモデルを評価 (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルの評価するため、BLEUを算出\n",
    "\n",
    "* BlEUとは翻訳の客観的評価に使用される指標で、答えとなる文章との一致率を評価する方法を用いています。\n",
    "詳しく知りたい方は下記をご覧ください。\n",
    "http://www2.nict.go.jp/univ-com/multi_trans/member/mutiyama/corpmt/4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd_corpus = \"mteval-corpus  -e BLEU RIBES -r \" +parameter_dict[\"reference_target\"] + \" -h \" + parameter_dict[\"test_target\"]\n",
    "cmd_sentence = \"mteval-sentence  -e BLEU RIBES -r \" +parameter_dict[\"reference_target\"] + \" -h \" + parameter_dict[\"test_target\"]\n",
    "mteval_corpus = subprocess.Popen(cmd_corpus, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout_data = mteval_corpus.stdout.read()\n",
    "print(stdout_data.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
